{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMMXOjEqS7OY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c4089a-22ba-4eb7-8837-87c8c2a5c27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: asyncpraw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (24.1.0)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (3.11.14)\n",
            "Requirement already satisfied: aiosqlite<=0.17.0 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (0.17.0)\n",
            "Requirement already satisfied: asyncprawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.18.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from update_checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "pip install asyncpraw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bml4hUf-bnD9",
        "outputId": "7051b0c5-db3b-4bbf-919b-724d25ffb7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import nest_asyncio\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "LIU61efYbsIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "Vxub9qi--qYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['olmo', 'registration']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('olmo_registration_1.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fiGOUbKS45X",
        "outputId": "7381de48-9e3e-44a3-ae19-75f27d1e876c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                  Title\n",
            "0                                                                                                                                                                                                                                                                                                                                                                          Barcelona 1:1 outlook for the Summer 2025/26\n",
            "1  **Media reliability report:**\\n\\n- **Tier 2**: Catalunya Radio ([@Catradioesports](https://xcancel.com/Catradioesports)) - reliable\\n\\n---\\n\\n[What is this?](https://www.reddit.com/r/Barca/wiki/reliability) | [Media Reliability Guide](https://barca-reddit.github.io) | [Feedback](https://www.reddit.com/message/compose/?to=/r/Barca) | [Source code](https://github.com/barca-reddit/barca-reddit.github.io)\n",
            "2                                                                                                                                                                         In my opinion this is just an article to make some noise and create panic. I think it doesnâ€™t change much. We knew the situation was going to be tight anyway, and that our spending this summer would be limited, so nothing to worry about.\n",
            "3                                                                                                                                                                         Renewals will obviously always increase salary mass, but we do have several expected to leave. Even if we don't make a major money signing, I am okay with that. I dont want a Barto 2.0 where we dig a bigger deficit with reckless spending\n",
            "4                                                                                                                                                                                                                                                                                                                                                                                                      No signing then?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Laliga\"\n",
        "    )\n",
        "\n",
        "    keywords = ['olmo', 'registration']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Laliga\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('olmo_registration_2.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGHgIbKVzEwL",
        "outputId": "09307de4-a274-4a59-d86b-b19ebd1b98e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/FCBarcelona\"\n",
        "    )\n",
        "\n",
        "    keywords = ['olmo', 'registration']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"FCBarcelona\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('olmo_registration_3.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiE2IW5GzUNC",
        "outputId": "ed418291-f0ff-4e8b-b5be-e77c6f17cca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/RealMadrid\"\n",
        "    )\n",
        "\n",
        "    keywords = ['olmo', 'registration']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"RealMadrid\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('olmo_registration_4.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA-g-c2o13L_",
        "outputId": "c2837a90-05b1-4258-80f1-8a57ee39c6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Football\"\n",
        "    )\n",
        "\n",
        "    keywords = ['olmo', 'registration']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Football\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('olmo_registration_5.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMri_Ffq0U2Q",
        "outputId": "33203a29-a5db-499f-c4f4-fe223170d304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                    Title\n",
            "0  Do you think Barcelona would still sign & register Olmo six months ago if the ongoing development of his non registration was foreseeable as an unavoidable certainty?\n",
            "1  Do you think Barcelona would still sign & register Olmo six months ago if the ongoing development of his non registration was foreseeable as an unavoidable certainty?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = ['olmo_registration_1.csv','olmo_registration_2.csv','olmo_registration_3.csv','olmo_registration_4.csv','olmo_registration_5.csv']\n",
        "for i in csv_files:\n",
        "  try:\n",
        "    dd=pd.read_csv(i)\n",
        "    print(dd.shape)\n",
        "  except pd.errors.EmptyDataError:\n",
        "    print(\"Empty Dataframe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-MWKqrE1-Td",
        "outputId": "6c4a4f50-ef7e-425f-c62c-5b433c2921f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 1)\n",
            "Empty Dataframe\n",
            "Empty Dataframe\n",
            "Empty Dataframe\n",
            "(2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = ['olmo_registration_1.csv','olmo_registration_5.csv']\n",
        "\n",
        "# Read all CSV files and combine them into one DataFrame\n",
        "df_list = [pd.read_csv(file) for file in csv_files]\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "combined_df.to_csv(\"merged_olmo_reg_data.csv\", index=False)\n",
        "\n",
        "print(\"Merged CSV files!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh051IPo-sXv",
        "outputId": "1968564d-cf20-447b-93e9-53c92bd6e94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged CSV files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxucxTOCD1B8",
        "outputId": "68fdf9a4-25c3-4aef-e33c-2581f4a08757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(242, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['ffp', '1:1','financial fair play']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if any(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('ffp_1.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRGMPv8g64Ua",
        "outputId": "9186d388-f2b1-4cf2-8dda-72fe4eed8b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                                                                           Title\n",
            "0                                                                                                                                              Without La Ligaâ€™s FFP, Bartomeu Could Have Pushed Barcelona Even Deeper Into Debt\n",
            "1                      La Liga FFP did not really stop Bartomeu from spending stupidly. In the end, the only year where Bartomeu's board was affected was the last one, when they were already on the verge of being kicked out.\n",
            "2  Covid stopped Bartomeu. Covid fucked our revenues so bad that the debt and the wages cost became evident. Covid fastracked Bartos removal by 2 years. If it had not happened, we would be in a much much worse position today\n",
            "3                                                                                            No, the thing is that even with the FFP Tebas allowed all of Bartomeuâ€™s shady deals to go through so he could create a bigger mess.\n",
            "4              We didnt go even deeper because of the mocio de censura which saved the club, La Liga allowed Bartomeus movements every single year he was president. \\n\\nPuta Bartomeu cagarÃ© sobre tu tumba, espero que pronto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp=pd.read_csv('ffp_1.csv')\n",
        "print(pp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MWY7jwa8tfo",
        "outputId": "4aee2c8c-1320-4501-98b6-e75e249dbdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1886, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['inigo', 'contract']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('contracts_1.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT8H4c1-9E_u",
        "outputId": "43a1d260-5aae-410a-d5aa-4b9745e87fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                                                                                                                                                                                                                          Title\n",
            "0                                                                                                                                                                                                                                                                                                                          Inigo Martinez's contract is almost up, do we renew?\n",
            "1                                                                                                                                                                                             It was confirmed a few weeks ago heâ€™s renewing til 2026\\n\\nhttps://preview.redd.it/ylekdtm0m6oe1.jpeg?width=1320&format=pjpg&auto=webp&s=fef35575ab3eda532a37f67d50d14c81c3aba4c9\n",
            "2                                                                                                                                                                                              We can't leave Inigo man. He has been solid and also we need not make the same mistakes again. Let him stay, rotate and make the transition smoother for Tah and the future CBs.\n",
            "3  Inigo Martinez has been our best centre back this season, so there is no reason not to offer him a new contract. Heâ€™s calm, versatile, good tackler, good at setting up the offside trap, good in aerial duels,â€¦ the list goes on.\\n\\nItâ€™s as if heâ€™s in his prime at his age, I still regret we didnâ€™t sign him way earlier when Barca was interested in him 7-8 years ago.\n",
            "4                                                                                                                                                                                                             The answer is Yes. What is the question? \\n\\nhttps://preview.redd.it/cnjfz48sl6oe1.png?width=1158&format=png&auto=webp&s=cf9d082abfa22ad6602bc59016f02c7d3efbeb5e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['cubarsi', 'contract']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('contracts_2.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUh5cD0d_IpE",
        "outputId": "bb1e6591-5fb5-42f2-bb83-69400332f147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                                                                                                                                                                                                                          Title\n",
            "0                                                                                                                                                                                                                                                                                                                          Inigo Martinez's contract is almost up, do we renew?\n",
            "1                                                                                                                                                                                             It was confirmed a few weeks ago heâ€™s renewing til 2026\\n\\nhttps://preview.redd.it/ylekdtm0m6oe1.jpeg?width=1320&format=pjpg&auto=webp&s=fef35575ab3eda532a37f67d50d14c81c3aba4c9\n",
            "2                                                                                                                                                                                              We can't leave Inigo man. He has been solid and also we need not make the same mistakes again. Let him stay, rotate and make the transition smoother for Tah and the future CBs.\n",
            "3  Inigo Martinez has been our best centre back this season, so there is no reason not to offer him a new contract. Heâ€™s calm, versatile, good tackler, good at setting up the offside trap, good in aerial duels,â€¦ the list goes on.\\n\\nItâ€™s as if heâ€™s in his prime at his age, I still regret we didnâ€™t sign him way earlier when Barca was interested in him 7-8 years ago.\n",
            "4                                                                                                                                                                                                             The answer is Yes. What is the question? \\n\\nhttps://preview.redd.it/cnjfz48sl6oe1.png?width=1158&format=png&auto=webp&s=cf9d082abfa22ad6602bc59016f02c7d3efbeb5e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['gavi', 'contract']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('contracts_3.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RAKFCCp_MCn",
        "outputId": "d3715041-470d-4521-d5c7-b076da9f6376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                           Title\n",
            "0                                                                                                                          Time to cash in on two midfielders? Unpopular Opinion\n",
            "1                                                    Selling gavi goes against what this club should stand for. Imagine if we sold pedri 3 years ago just cuz we needed money...\n",
            "2  60 plus games each season. Atleast one midfielder is always injured.\\n\\nSo no, we donâ€™t need to sell anyone. We have the perfect midfield, idk why you all want to change it.\n",
            "3                                                                                                                                               ![gif](giphy|fXnRObM8Q0RkOmR5nf)\n",
            "4                                                                                                                                    How may languages can everyone say \"no\" in?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['pedri', 'contract']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('contracts_4.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xo3R4io_O7t",
        "outputId": "36eb12e0-0d85-4f3f-8268-40513a9eff00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                           Title\n",
            "0                                                                                                                          Time to cash in on two midfielders? Unpopular Opinion\n",
            "1                                                    Selling gavi goes against what this club should stand for. Imagine if we sold pedri 3 years ago just cuz we needed money...\n",
            "2  60 plus games each season. Atleast one midfielder is always injured.\\n\\nSo no, we donâ€™t need to sell anyone. We have the perfect midfield, idk why you all want to change it.\n",
            "3                                                                                                                                               ![gif](giphy|fXnRObM8Q0RkOmR5nf)\n",
            "4                                                                                                                                    How may languages can everyone say \"no\" in?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply to support nested event loops in Colab/Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Authenticate and fetch Reddit posts with comments\n",
        "async def fetch_posts(subreddit_name, start_date, end_date, limit=1000):\n",
        "    reddit = asyncpraw.Reddit(\n",
        "        client_id=\"MYNOOD7DfAOi2d_cgOjjQA\",\n",
        "        client_secret=\"eYeW8h60Seb37K_BQW9kk6_9IPx6AA\",\n",
        "        user_agent=\"r/Barca\"\n",
        "    )\n",
        "\n",
        "    keywords = ['araujo', 'contract']\n",
        "    start_timestamp = int(datetime.strptime(start_date, \"%d%m%Y\").timestamp())\n",
        "    end_timestamp = int(datetime.strptime(end_date, \"%d%m%Y\").timestamp())\n",
        "\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    categories = [\"top\", \"new\", \"hot\", \"controversial\"]\n",
        "\n",
        "    all_posts = []\n",
        "\n",
        "    for category in categories:\n",
        "        print(f\"Fetching {category} posts...\")\n",
        "        async for post in getattr(subreddit, category)(limit=5000):\n",
        "            post_time = int(post.created_utc)\n",
        "            post_title = post.title.lower()\n",
        "            post_body = (post.selftext or \"\").lower()\n",
        "\n",
        "            if all(keyword.lower() in post_title or keyword.lower() in post_body for keyword in keywords):\n",
        "                if start_timestamp <= post_time <= end_timestamp:\n",
        "                    if \"reddit.com\" in post.url:\n",
        "                        # Load all comments\n",
        "                        await post.load()\n",
        "                        await post.comments.replace_more(limit=None)\n",
        "                        comments = [comment.body for comment in post.comments.list()]\n",
        "\n",
        "                        all_posts.append({\"Title\": post.title})\n",
        "                        for i in comments:\n",
        "                          all_posts.append({\"Title\": i})\n",
        "\n",
        "            if len(all_posts) >= limit * len(categories):\n",
        "                break\n",
        "\n",
        "    await reddit.close()\n",
        "    return pd.DataFrame(all_posts)\n",
        "\n",
        "# Async runner\n",
        "async def main():\n",
        "    subreddit_name = \"Barca\"\n",
        "    start_date = \"01082024\"\n",
        "    end_date = \"22032025\"\n",
        "\n",
        "    posts_df = await fetch_posts(subreddit_name, start_date, end_date, limit=1000)\n",
        "    print(posts_df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    posts_df.to_csv('contracts_5.csv', index=False)\n",
        "\n",
        "# Run it\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJoo9Zru_SMj",
        "outputId": "3b689eb5-9942-4ce7-bc95-e881ace4f23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching top posts...\n",
            "Fetching new posts...\n",
            "Fetching hot posts...\n",
            "Fetching controversial posts...\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                  Title\n",
            "0                                                                                                                                                                                                                                                                                                                                                                          Barcelona 1:1 outlook for the Summer 2025/26\n",
            "1  **Media reliability report:**\\n\\n- **Tier 2**: Catalunya Radio ([@Catradioesports](https://xcancel.com/Catradioesports)) - reliable\\n\\n---\\n\\n[What is this?](https://www.reddit.com/r/Barca/wiki/reliability) | [Media Reliability Guide](https://barca-reddit.github.io) | [Feedback](https://www.reddit.com/message/compose/?to=/r/Barca) | [Source code](https://github.com/barca-reddit/barca-reddit.github.io)\n",
            "2                                                                                                                                                                         In my opinion this is just an article to make some noise and create panic. I think it doesnâ€™t change much. We knew the situation was going to be tight anyway, and that our spending this summer would be limited, so nothing to worry about.\n",
            "3                                                                                                                                                                         Renewals will obviously always increase salary mass, but we do have several expected to leave. Even if we don't make a major money signing, I am okay with that. I dont want a Barto 2.0 where we dig a bigger deficit with reckless spending\n",
            "4                                                                                                                                                                                                                                                                                                                                                                                                      No signing then?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = ['contracts_1.csv','contracts_2.csv','contracts_3.csv','contracts_4.csv','contracts_5.csv']\n",
        "\n",
        "for k in csv_files:\n",
        "  cp=pd.read_csv(k)\n",
        "  print(cp.shape)\n",
        "# Read all CSV files and combine them into one DataFrame\n",
        "df_list = [pd.read_csv(file) for file in csv_files]\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "print(combined_df.shape)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "combined_df.to_csv(\"merged_contract_data.csv\", index=False)\n",
        "\n",
        "print(\"Merged CSV files!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL1ody-S_lSt",
        "outputId": "7f6ece8d-0df8-4a02-c567-131fa9ecd4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(171, 1)\n",
            "(171, 1)\n",
            "(1623, 1)\n",
            "(1571, 1)\n",
            "(1689, 1)\n",
            "(5225, 1)\n",
            "Merged CSV files!\n"
          ]
        }
      ]
    }
  ]
}